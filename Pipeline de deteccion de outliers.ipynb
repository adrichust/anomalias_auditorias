{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ade25c",
   "metadata": {},
   "source": [
    "# Pipeline de Análisis de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a726fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns; sns.set()\n",
    "# sns.set_style('darkgrid', {'axes.facecolor': '.9'})\n",
    "# %matplotlib inline\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "from scipy.stats.mstats import winsorize\n",
    "import statistics\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Configuracion warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Semilla de aleatorizacion\n",
    "# ==============================================================================\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2fa4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES PARA ENTRENAR LOS DISTINTOS MODELOS DE DETECCION\n",
    "def EntrenarIF(datos, ruta_modelo):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo Isolation Forest y guardarlo en la direccion dada.\n",
    "    \n",
    "    datos (pandas.df) = datos de entrenamiento\n",
    "    ruta_modelo (str) = nombre del fichero en el que se guardara el modelo. Debe acabar en .sav\n",
    "    \"\"\"\n",
    "    #Definicion y entrenamiento del iforest\n",
    "    modelo_iforest = IsolationForest(n_estimators = 1000,\n",
    "                                     max_samples = 0.75,\n",
    "                                     contamination = 0.01,\n",
    "                                     n_jobs = -1,\n",
    "                                     random_state = SEED)\n",
    "    modelo_iforest = modelo_iforest.fit(X = datos)\n",
    "    #Guardar el modelo entrenado\n",
    "    pickle.dump(modelo_iforest, open(ruta_modelo, \"wb\"))\n",
    "    \n",
    "    return modelo_iforest\n",
    "\n",
    "\n",
    "def EntrenarMCD(datos, ruta_modelo):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo MCD y guardarlo en la direccion dada.\n",
    "    \n",
    "    datos (pandas.df) = datos de entrenamiento\n",
    "    ruta_modelo (str) = nombre del fichero en el que se guardara el modelo. Debe acabar en .sav\n",
    "    \"\"\"\n",
    "    #Definicion y entrenamiento del iforest\n",
    "    modelo_mcd = EllipticEnvelope(contamination = 0.01,\n",
    "                                  random_state = SEED)\n",
    "    modelo_mcd = modelo_mcd.fit(X = datos)\n",
    "    #Guardar el modelo entrenado\n",
    "    pickle.dump(modelo_mcd, open(ruta_modelo, \"wb\"))\n",
    "    \n",
    "    return modelo_mcd\n",
    "\n",
    "\n",
    "def EntrenarLOF(datos, ruta_modelo):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo LOF y guardarlo en la direccion dada.\n",
    "    \n",
    "    datos (pandas.df) = datos de entrenamiento\n",
    "    ruta_modelo (str) = nombre del fichero en el que se guardara el modelo. Debe acabar en .sav\n",
    "    \"\"\"\n",
    "    #Definicion y entrenamiento del iforest\n",
    "    modelo_lof = LocalOutlierFactor(novelty=True)\n",
    "    modelo_lof = modelo_lof.fit(X = datos)\n",
    "    #Guardar el modelo entrenado\n",
    "    pickle.dump(modelo_lof, open(ruta_modelo, \"wb\"))\n",
    "    \n",
    "    return modelo_lof\n",
    "\n",
    "\n",
    "def EntrenarSVM(datos, ruta_modelo):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo SVM y guardarlo en la direccion dada.\n",
    "    \n",
    "    datos (pandas.df) = datos de entrenamiento\n",
    "    ruta_modelo (str) = nombre del fichero en el que se guardara el modelo. Debe acabar en .sav\n",
    "    \"\"\"\n",
    "    #Definicion y entrenamiento del iforest\n",
    "    modelo_svm = OneClassSVM(nu=0.01)\n",
    "    modelo_svm = modelo_svm.fit(X = datos)\n",
    "    #Guardar el modelo entrenado\n",
    "    pickle.dump(modelo_svm, open(ruta_modelo, \"wb\"))\n",
    "    \n",
    "    return modelo_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209144b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES AUXILIARES PARA DETERMINAR OUTLIERS EN FUNCION DEL IQR Y VISUALIZAR SCORES\n",
    "def CrearDirectorio(path):\n",
    "    \"\"\"\n",
    "    Comprobar si un directorio existe y, si no es asi, crearlo.\n",
    "    \n",
    "    path (str) = directorio que se quiere crear\n",
    "    \"\"\"\n",
    "    dir_existe = os.path.exists(path)\n",
    "    if not dir_existe:\n",
    "        os.makedirs(path)\n",
    "    return\n",
    "\n",
    "\n",
    "def ValorarScoresIQR(scores, verbose = True):\n",
    "    \"\"\"\n",
    "    Funcion para determinar a partir de que score de una TDA se declara un dato como anomalo\n",
    "    usando el rango intercuartilico (IQR).\n",
    "    Devuelve una lista de bool que dice si los datos son anomalos (True) y el umbral para la score.\n",
    "    \"\"\"\n",
    "    #Obtener el IQR\n",
    "    Q1 = np.percentile(scores, 25)\n",
    "    Q3 = np.percentile(scores, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    scores = scores.tolist()\n",
    "    #Umbral inferior e indices\n",
    "    umbral = Q1 - 3 * IQR\n",
    "    outs = list(scores <= umbral)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"- Sobrepasan el umbral:\", sum(outs))\n",
    "    \n",
    "    return outs, umbral\n",
    "\n",
    "\n",
    "def HistUmbrales(scores, umbral):\n",
    "    \"\"\"\n",
    "    Funcion para mostrar el histograma de las scores de un modelo de deteccion de anomalias\n",
    "    junto con los umbrales inferior y superior.\n",
    "    \n",
    "    scores (list) = puntuacion de anomalia de los puntos del dataset\n",
    "    umbral_sup (float) = valor a partir del cual una observacion es considerada anomalia\n",
    "    umbral_inf (float) = valor por debajo del cual una observacion es considerada anomalia\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "    sns.distplot(scores, hist=True, kde=True, \n",
    "                 color = 'blue', \n",
    "                 hist_kws = {'edgecolor':'black'},\n",
    "                 kde_kws = {'linewidth': 2},\n",
    "                 ax = ax\n",
    "                )\n",
    "    ax.axvline(umbral, c='red', linestyle='--') #umbral\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def EvaluarModelo(modelo, datos, verbose = True, visualizar = True):\n",
    "    \"\"\"\n",
    "    Generar scores de anomalia con un modelo entrenado y evaluarlas. Los modelos\n",
    "    pueden ser de Isolation Forest, MCD, LOF o SVM.\n",
    "    \n",
    "    modelo = modelo entrenado\n",
    "    datos = datos sobre los que realizar la evaluacion\n",
    "    \"\"\"\n",
    "    #Obtener las scores de las muestras y los outliers\n",
    "    scores = modelo.score_samples(X = datos)\n",
    "    idx_out, umbral = ValorarScoresIQR(scores, verbose)\n",
    "    \n",
    "    if visualizar:\n",
    "        HistUmbrales(scores, umbral)\n",
    "    \n",
    "    return scores, idx_out, umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2857518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION PARA ENTRENAR LAS TDA ELEGIDAS\n",
    "def EntrenarTDA(datos, rutas_modelos):\n",
    "    \"\"\"\n",
    "    Entrenar todas las TDA, calcular las scores, obtener umbrales a partir de los cuales\n",
    "    se determine como outlier a cada observacion, guardar los datos declarados como outlier\n",
    "    por cada tecnica separados y obtener los indices de los mismos.\n",
    "    \"\"\"\n",
    "    #Comprobar si directorio modelos existe\n",
    "    CrearDirectorio(path = \"./modelos/\")\n",
    "    #Entrenar modelos de todas las TDAs\n",
    "    modelo_if = EntrenarIF(datos, rutas_modelos[0])\n",
    "    modelo_mcd = EntrenarMCD(datos, rutas_modelos[1])\n",
    "    modelo_lof = EntrenarLOF(datos, rutas_modelos[2])\n",
    "    modelo_svm = EntrenarSVM(datos, rutas_modelos[3])\n",
    "    \n",
    "    #Obtener scores modelos y visualizar si se quiere\n",
    "    scores_if, idx_out_if, umbral_if = EvaluarModelo(modelo_if, datos)\n",
    "    scores_mcd, idx_out_mcd, umbral_mcd = EvaluarModelo(modelo_mcd, datos)\n",
    "    scores_lof, idx_out_lof, umbral_lof = EvaluarModelo(modelo_lof, datos)\n",
    "    scores_svm, idx_out_svm, umbral_svm = EvaluarModelo(modelo_svm, datos)\n",
    "    \n",
    "    #Añadir puntuaciones de los distintos metodos\n",
    "    datos[\"scores_if\"] = scores_if\n",
    "    datos[\"scores_mcd\"] = scores_mcd\n",
    "    datos[\"scores_lof\"] = scores_lof\n",
    "    datos[\"scores_svm\"] = scores_svm\n",
    "    \n",
    "    #Comprobar que el directorio para outliers existe\n",
    "    CrearDirectorio(path = \"./outliers/\")\n",
    "    #Obtener muestras outliers y guardarlas separadas\n",
    "    lista_idx = [idx_out_if, idx_out_mcd, idx_out_lof, idx_out_svm]\n",
    "    lista_outs = list()\n",
    "    for idx in lista_idx:\n",
    "        lista_outs.append(datos.iloc[idx,])\n",
    "    #Guardar cada conjunto de outliers con un nombre distinto\n",
    "    nom_modelos = [\"iforest\", \"mcd\", \"lof\", \"svm\"]\n",
    "    for i in range(len(nom_modelos)):\n",
    "        direccion = \"./outliers/datos_\" + nom_modelos[i] + \".xlsx\"\n",
    "        lista_outs[i].to_excel(direccion)\n",
    "    \n",
    "    return lista_idx, datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656fc82",
   "metadata": {},
   "source": [
    "## Análisis de Outliers Unidimensionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af80fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar primero outliers por variable\n",
    "outs, umbral = ValorarScoresIQR(df[variable])\n",
    "#Guardamos los datos sin outliers por importe\n",
    "bool_mask = [not elem for elem in outs]\n",
    "df_clean = df.iloc[bool_mask]\n",
    "\n",
    "print(\"Tamaño actual de los datos:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881631c",
   "metadata": {},
   "source": [
    "## Análisis de Outliers con TDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "rutas_modelos = [\"./modelos/modelo_ifo_datos.sav\", \"./modelos/modelo_mcd_datos.sav\",\n",
    "                 \"./modelos/modelo_lof_datos.sav\", \"./modelos/modelo_svm_datos.sav\"]\n",
    "lista_idx, df_scores = EntrenarTDA(df_clean, rutas_modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear columnas de ordenación por método\n",
    "cols_scores = [\"scores_if\", \"scores_mcd\", \"scores_lof\", \"scores_svm\"]\n",
    "cols_orden = [\"orden_if\", \"orden_mcd\", \"orden_lof\", \"orden_svm\"]\n",
    "for i in range(len(cols_scores)):\n",
    "    df_scores = df_scores.sort_values(cols_scores[i])\n",
    "    df_scores[cols_orden[i]] = range(1, len(df_scores) + 1)\n",
    "\n",
    "#Crear columna que combine el orden de outliers para todas las TDA\n",
    "df_scores[\"orden_global\"] = [0] * df_scores.shape[0] #columna de 0\n",
    "for col in cols_orden:\n",
    "    df_scores[\"orden_global\"] = df_scores[\"orden_global\"] + df_scores[col]\n",
    "\n",
    "df_scores = df_scores.sort_values(\"ID\")\n",
    "#Unir a los datos originales todas las columnas obtenidas\n",
    "df_final = pd.merge(df, df_scores, on=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107822f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar resultados\n",
    "df_final.to_excel(\"../data/datos_anomalias.xlsx\", index = True) #index True si contiene el id como indice"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03ff50280649e48ad0c31ff4d8c7b6c289aa1c236bd5b29a71992b83ffd5cb40"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
